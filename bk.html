<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8">
  	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title> Pure WorkTile</title>
</head>
<link href="./src/pure.css" rel="stylesheet">
<link href="./src/styles.css" rel="stylesheet">
<style>

.pure-button-group .pure-button {
    letter-spacing: normal;
    word-spacing: normal;
    vertical-align: top;
    text-rendering: auto;
}

/*csslint outline-none:false*/

.pure-button {
    font-family: inherit;
    font-size: 100%;
    padding: 0.5em 1em;
    color: #444; /* rgba not supported (IE 8) */
    color: rgba(0, 0, 0, 0.80); /* rgba supported */
    border: 1px solid #999;  /*IE 6/7/8*/
    border: none rgba(0, 0, 0, 0);  /*IE9 + everything else*/
    background-color: #E6E6E6;
    text-decoration: none;
    border-radius: 2px;
}
.button-success,
.button-error,
.button-warning,
.button-secondary {
    color: white;
    border-radius: 4px;
    text-shadow: 0 1px 1px rgba(0, 0, 0, 0.2);
}
.button-success {
    background: rgb(28, 184, 65); /* this is a green */
}
.button-error {
    background: rgb(202, 60, 60); /* this is a maroon */
}

.button-warning {
    background: rgb(223, 117, 20); /* this is an orange */
}

.button-secondary {
    background: rgb(66, 184, 221); /* this is a light blue */
}
.marginTop {
	margin-top:40px;
}
.marginR {
	margin-right: 24px;
}
</style>
<body>
	<audio src="" autoplay controls></audio></br>
	<!--<video src=""></video>-->
	<button class="pure-button button-warning" id="connect">CONNETING..</button></br>
	<button class="button-success pure-button" id="voice" style="margin-top:10px;width:140px;height:36px;"></button>
	</br>
	<p id="progress" style="display: none;">recording...</p>

	<div class="pure-g marginTop">
		<div class="pure-u-1-2 button-success marginR"><h2>Heading</h2>
			<div>This is content.<br>
				<video src="" controls></video>
			</div>
		</div>
		<div class="pure-u-1-2 button-secondary"><h2>Heading</h2>
			<div>This is content2.<br>
				<video src="" controls></video> <br>
				This is the end...
			</div>
		</div>
	<div>
	<div class="pure-u-1-1 button-warning">
		<div class="">
			<h2>Heading</h2>
			This is content3.
		</div>
	</div>
	<br>

	<div style="width:36px;height:36px;border:1px solid #000; position: relative;overflow: hidden;">
		<img src="./assets/sprite@2x.png" style="position:absolute;left:-396px;top:-352px;">
		</div>
	<!--<button class="pure-button pure-button-warn">PIC</button>-->
	<!--<script src="./src/wsapp.js"></script>-->
	<script>
		// client app to chat with audio.
		navigator.getUserMedia = navigator.getUserMedia ||
								navigator.webkitGetUserMedia ||
								navigator.mozGetUserMedia;
		var con = document.getElementById("connect");
		var voice = document.getElementById("voice");
		var progress = document.getElementById("progress");
		var audio = document.querySelector("audio");
		// 先给关键变量占个位置.
		var gRecorder = null;
		var door = false;
		var ws = null;

		con.onclick = function() {
			if(!navigator.getUserMedia) {
				alert("UserMedia not supported");
				return;
			}
			// 静态方法.. 把recorder 交给全局变量.
			SRecorder.get(function(rec) {
				gRecorder = rec;
			})

			// 准备连接 WebSocket.
			ws = new WebSocket("wss://123.206.201.245:8888");
			ws.onopen = function() {
				console.log("connected to websocket server...");
				con.innerText = "CONNECTED!";
				// con.style.background = "green";
				con.style.color = "white";
				ws.send("user: Audience" + (Math.random()*1000).toFixed(0));
			}
			ws.onmessage = function(e) {
				// 接收音频数据并播放.
				receive(e.data);
			}
			// 监听录音按钮
			voice.onmousedown = function(e) {
				if(!door) {
					gRecorder.start();
					door = true;
				}     
			};

			voice.onmouseup = function(e) {
				if(door) {
					try {
						// 向服务器发送处理过的音频二进制流.
						ws.send(gRecorder.getBlob());
						gRecorder.clear();
						gRecorder.stop();
						door = false;
					}					
					catch(e) {						
					}
				}
			}

			voice.ontouchstart = function(e) {
				if(!door) {
					gRecorder.start();
					door = true;
					progress.style.display = "block";
				}
			}
			voice.ontouchend = function(e) {
				if(door) {
					try {
						// 向服务器发送处理过的音频二进制流.
						ws.send(gRecorder.getBlob());
						gRecorder.clear();
						gRecorder.stop();
						door = false;
						progress.style.display = "none";
					}					
					catch(e) {						
					}
				}
			}

		}

		// Capsulate Audio　Process. SRecorder is an Object to handle Audio !!
		var SRecorder = function(stream) {
			config = {};
			config.sampleBits = config.sampleBits || 8;
			config.sampleRate = config.sampleRate || (44100/6);

			var context = new AudioContext();
			// MicroPhone Input Object
			var audioInput = context.createMediaStreamSource(stream);
			// audio collector. 
			// Creates a ScriptProcessorNode, which can be used for direct audio processing via JavaScript.
			var recorder = context.createScriptProcessor(4096, 1, 1);

			var audioData = {
				size: 0          //录音文件长度
				, buffer: []     //录音缓存
				, inputSampleRate: context.sampleRate    //输入采样率
				, inputSampleBits: 16       //输入采样数位 8, 16
				, outputSampleRate: config.sampleRate    //输出采样率
				, oututSampleBits: config.sampleBits       //输出采样数位 8, 16
				, clear: function() {
					this.buffer = [];
					this.size = 0;
				}
				, input: function (data) {
					this.buffer.push(new Float32Array(data));
					this.size += data.length;
				}
				, compress: function () { //合并压缩
					//合并
					var data = new Float32Array(this.size);
					var offset = 0;
					for (var i = 0; i < this.buffer.length; i++) {
						data.set(this.buffer[i], offset);
						offset += this.buffer[i].length;
					}
					//压缩
					var compression = parseInt(this.inputSampleRate / this.outputSampleRate);
					var length = data.length / compression;
					var result = new Float32Array(length);
					var index = 0, j = 0;
					while (index < length) {
						result[index] = data[j];
						j += compression;
						index++;
					}
					return result;
				}
				, encodeWAV: function () {
					var sampleRate = Math.min(this.inputSampleRate, this.outputSampleRate);
					var sampleBits = Math.min(this.inputSampleBits, this.oututSampleBits);
					var bytes = this.compress();
					var dataLength = bytes.length * (sampleBits / 8);
					var buffer = new ArrayBuffer(44 + dataLength);
					var data = new DataView(buffer);

					var channelCount = 1;//单声道
					var offset = 0;

					var writeString = function (str) {
						for (var i = 0; i < str.length; i++) {
							data.setUint8(offset + i, str.charCodeAt(i));
						}
					};

					// 资源交换文件标识符 
					writeString('RIFF'); offset += 4;
					// 下个地址开始到文件尾总字节数,即文件大小-8 
					data.setUint32(offset, 36 + dataLength, true); offset += 4;
					// WAV文件标志
					writeString('WAVE'); offset += 4;
					// 波形格式标志 
					writeString('fmt '); offset += 4;
					// 过滤字节,一般为 0x10 = 16 
					data.setUint32(offset, 16, true); offset += 4;
					// 格式类别 (PCM形式采样数据) 
					data.setUint16(offset, 1, true); offset += 2;
					// 通道数 
					data.setUint16(offset, channelCount, true); offset += 2;
					// 采样率,每秒样本数,表示每个通道的播放速度 
					data.setUint32(offset, sampleRate, true); offset += 4;
					// 波形数据传输率 (每秒平均字节数) 单声道×每秒数据位数×每样本数据位/8 
					data.setUint32(offset, channelCount * sampleRate * (sampleBits / 8), true); offset += 4;
					// 快数据调整数 采样一次占用字节数 单声道×每样本的数据位数/8 
					data.setUint16(offset, channelCount * (sampleBits / 8), true); offset += 2;
					// 每样本数据位数 
					data.setUint16(offset, sampleBits, true); offset += 2;
					// 数据标识符 
					writeString('data'); offset += 4;
					// 采样数据总数,即数据总大小-44 
					data.setUint32(offset, dataLength, true); offset += 4;
					// 写入采样数据 
					if (sampleBits === 8) {
						for (var i = 0; i < bytes.length; i++, offset++) {
							var s = Math.max(-1, Math.min(1, bytes[i]));
							var val = s < 0 ? s * 0x8000 : s * 0x7FFF;
							val = parseInt(255 / (65535 / (val + 32768)));
							data.setInt8(offset, val, true);
						}
					} else {
						for (var i = 0; i < bytes.length; i++, offset += 2) {
							var s = Math.max(-1, Math.min(1, bytes[i]));
							data.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
						}
					}

					return new Blob([data], { type: 'audio/wav' });
				}
			}

			this.start = function() {
				// connect Nodes.
				audioInput.connect(recorder);
				recorder.connect(context.destination);
			}

			this.stop = function() {
				recorder.disconnect();
			}

			this.getBlob = function() {
				return audioData.encodeWAV();
			}

			this.clear = function() {
				audioData.clear();
			}

			// listen User Recording Proccess !
			recorder.onaudioprocess = function(e) {
				// audioData is Custom Object with encodeWAV function!!
				audioData.input(e.inputBuffer.getChannelData(0));
				// After recording, then AudioBuffer should be sent by frames..
				// audioData.encodeWAV();
			}
		}

		SRecorder.get = function(callback) {
			if (callback) {
				if(navigator.getUserMedia) {
					navigator.getUserMedia({
						audio: true,
						// video: { width: 800, height: 600 }
					},
						function(stream){
							var rec = new SRecorder(stream);
							callback(rec);
							// var video = document.querySelector('video');
							// video.src = window.URL.createObjectURL(stream);
							// video.onloadedmetadata = function(e) {
							//     // video.play();
							//     console.log("onloaded metadata");
							// };
						}, function(){
							console.error("errorCallbck");
						})
				} else {
					alert("UserMedia not supported");
				}
			}
		}

		function receive(e) {
			// URL.create.. 这是个什么方法. e.是server 传过来的二进制音频文件,
			// 这个方法类似于把二进制文件标识上一个 URL 以便于audio 引用. 类似于Base64
			audio.src = window.URL.createObjectURL(e);
		}

	</script>
	<!--<app-root>Loading...</app-root>
<script type="text/javascript" src="inline.js"></script><script type="text/javascript" src="main.cee3aa69b89270235607.bundle.js"></script>-->
</body>
